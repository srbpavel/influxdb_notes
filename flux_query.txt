#UNIQUE ds ROM's
$ docker container exec -i -t dck_influxdb influx query 'from(bucket:"test_csv_ds") |> range(start:-1y) |> keep(columns:["DsId"])|> limit(n:3) |> unique(column: "DsId") |> group()' --skip-verify
Result: _result
Table: keys: []
           DsId:string  
----------------------  
         1052176647976  
          236134354984  
          841704586024  
          910462155048  
           96928329000


#COUNT RESULTS / need group() if more result tables 
$ docker container exec -i -t dck_influxdb influx query 'from(bucket:"test_csv_ds") |> range(start:-1y) |> keep(columns:["DsId"])|> unique(column: "DsId") |> group() |> count(column: "DsId")' --skip-verify
Result: _result
Table: keys: []
                  DsId:int  
--------------------------  
                         5


#SIMPLE map() / celsius -> kelvin / jen priklad, realne ti to rozhazi graf
#lepsi prepsal puvodni _value nez dalsi sloupec kelvin, pokud to teda nemam do tabulky kde spis hlidam cisla
#
conan@ruth:~/soft/labjack_switch_board$ docker container exec -i -t dck_influxdb influx query 'from(bucket:"test_csv_ds") |> range(start:-1y) |> map(fn: (r) => ({r with kelvin: (r._value + 273.15)})) |> limit(n: 1) |> keep(columns: ["_value", "kelvin"])' --skip-verify
Result: _result
Table: keys: []
                _value:float                  kelvin:float  
----------------------------  ----------------------------  
                     19.1875                      292.3375  
                      19.375                       292.525  
                     21.0625                      294.2125  
                     19.1875                      292.3375  
                       19.25                         292.4 


#MAP new column STATUS via if/else / HEMICHROMIS -> battery_hemichromis / single+double cell combo

voltage_limit = 6.85 //VOLTAGE

join(tables: {d1: sensor_id, d2: ul_id}, on: ["BatUlId"]) 

|> map(fn: (r) => ({
_time: r._time_d1,
_value: r._value_d1,
esp_machine_id: r.esp_machine_id,
nick_name: r._value_d2,
baterka: r.BatSenKey,
active: r.active,
type: r.type,
carrier: r.BatCarrier, 
valid: if r._value_d1 < voltage_limit then "low" else "high"
}))


#SOMEBODY NEEDED TO SEE LINES AS VISUAL BOARDES / my array solution + time_range
#can inject to ploted data, let's say DS temperature
#
import "experimental/array"
import "experimental"

limit = 20.0
offset = 1.0

upper_limit = limit + offset
lower_limit = limit - offset

upper = array.from(rows: [
{_measurement: "line", _field: "DsDecimal", _value: upper_limit, _time: now()},
{_measurement: "line", _field: "DsDecimal", _value: upper_limit, _time: experimental.addDuration(d: v.timeRangeStart, to: now(),)}
])
|>yield(name: "line_up")

lower = array.from(rows: [
{_measurement: "dallas", _field: "DsDecimal", _value: lower_limit, _time: now()},
{_measurement: "dallas", _field: "DsDecimal", _value: lower_limit, _time: experimental.addDuration(d: v.timeRangeStart, to: now(),)}
])
|>yield(name: "line_down")

#PROFILER / performance info
https://docs.influxdata.com/flux/v0.x/stdlib/profiler/
https://dganais.medium.com/tl-dr-influxdb-tech-tips-optimizing-flux-performance-in-influxdb-cloud-21de08fc50c9

#FLUX
import "profiler"
option profiler.enabledProfilers = ["query", "operator"]

#CLI
$ docker container exec -i -t dck_influxdb influx query 'import "profiler" option profiler.enabledProfilers = ["query", "operator"] from(bucket:"test_csv_ds") |> range(start:-1y) |> drop(columns:["_start", "_stop"]) |> group() |> count()' --skip-verify      

Result: _profiler
Table: keys: [_measurement]
   _measurement:string             Concurrency:int         CompileDuration:int           QueueDuration:int            PlanDuration:int         RequeueDuration:int         ExecuteDuration:int           TotalDuration:int            MaxAllocated:int          TotalAllocated:int    RuntimeErrors:string                                                                                                                                          flux/query-plan:string  influxdb/scanned-bytes:int  influxdb/scanned-values:int  
----------------------  --------------------------  --------------------------  --------------------------  --------------------------  --------------------------  --------------------------  --------------------------  --------------------------  --------------------------  ----------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------------  --------------------------  ---------------------------  
        profiler/query                           0                      288000                       18118                           0                           0                     9081229                     9412366                       49280                           0                          digraph {
  ReadRange5
  drop2
  group3
  count4
  generated_yield

  ReadRange5 -> drop2
  drop2 -> group3
  group3 -> count4
  count4 -> generated_yield
}

                           0                            0  
Table: keys: [_measurement]
   _measurement:string                             Type:string            Label:string                   Count:int             MinDuration:int             MaxDuration:int             DurationSum:int            MeanDuration:float  
----------------------  --------------------------------------  ----------------------  --------------------------  --------------------------  --------------------------  --------------------------  ----------------------------  
     profiler/operator              *influxdb.readFilterSource              ReadRange5                           1                     1054024                     1054024                     1054024                       1054024  
     profiler/operator           *universe.groupTransformation                  group3                           5                        3542                        9768                       27875                          5575  
     profiler/operator        *execute.aggregateTransformation                  count4                           1                       13318                       13318                       13318                         13318  
     profiler/operator  *universe.schemaMutationTransformation                   drop2                           5                       20701                       32589                      122182                       24436.4

#ADD SET + MAP to get more performance date
import "profiler" option profiler.enabledProfilers = ["query", "operator"] from(bucket:"test_csv_ds") |> range(start:-1y) |> set(key: "_measurement",value: "kelvin") |> map(fn: (r) => ({ r with _value: r._value + 273.15}))|> drop(columns:["_start", "_stop"])
